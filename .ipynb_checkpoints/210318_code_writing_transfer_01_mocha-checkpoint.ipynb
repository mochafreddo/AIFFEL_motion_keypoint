{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attended-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from math import cos, sin, pi\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dependent-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 이동\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "digital-puzzle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aug_rotation_noise_upsidedown.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_imgs.zip',\n",
       " 'baseline_submission.csv',\n",
       " 'baseline_with_augmentation.h5',\n",
       " 'train_df.csv',\n",
       " 'train_imgs',\n",
       " 'test_imgs',\n",
       " 'test_imgs.zip',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 중 10%를 검증 데이터로 사용\n",
    "\n",
    "# csv 파일 불러오기\n",
    "data = pd.read_csv('train_df.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 경로 설정\n",
    "data_paths = sorted(glob.glob('./train_imgs/*.jpg'))\n",
    "test_paths = sorted(glob.glob('./test_imgs/*.jpg'))\n",
    "\n",
    "data['path'] = data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intense-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 길이는:  3776\n",
      "검증 데이터 길이는:  419\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임 랜덤하게 분할\n",
    "\n",
    "# 전체 데이터 중 90%는 학습 데이터 활용\n",
    "train = data.sample(frac=0.9, random_state=2021)\n",
    "print('학습 데이터 길이는: ', len(train))\n",
    "\n",
    "# 전체 데이터 중 10%는 검증 데이터 활용\n",
    "valid = data.drop(train.index)\n",
    "print('검증 데이터 길이는: ', len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recovered-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator():\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])  # path(경로)를 통해 이미지 읽기\n",
    "        # 경로를 통해 불러온 이미지를 tensor로 변환\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])  # 이미지 resize\n",
    "        img = img/255\n",
    "        target = train.iloc[:, 1:49].iloc[i, :]  # keypoint 뽑아주기\n",
    "        target = target/4\n",
    "\n",
    "        yield (img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proved-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([270, 480, 3]), tf.TensorShape([48])))\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([270, 480, 3]), tf.TensorShape([48])))\n",
    "valid_dataset = valid_dataset.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aging-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "determined-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback 설정\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    factor=0.85,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(  # 에포크마다 현재 가중치를 저장\n",
    "    filepath=\"./model_checkpoint_callback_210318_{epoch}.h5\",  # 모델 파일 경로\n",
    "    monitor='val_loss',  # val_loss가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, model_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "standard-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    base_model = InceptionResNetV2(input_shape=(\n",
    "        270, 480, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu', input_dim=(7*13*1536))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    predictions = Dense(48)(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_210318.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "\n",
    "for test_path in tqdm(test_paths):\n",
    "    img=tf.io.read_file(test_path)\n",
    "    img=tf.image.decode_jpeg(img, channels=3)\n",
    "    img=tf.image.resize(img, [270,480])\n",
    "    img=img/255\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test=tf.stack(X_test, axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "# image size를 1920x1080 -> 480x270으로 바꿔서 예측했으므로 * 4\n",
    "submission.iloc[:, 1:] = pred*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "submission.to_csv('submission_210318_01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
